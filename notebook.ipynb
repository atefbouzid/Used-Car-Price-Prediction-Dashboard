{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7aa902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "\n",
    "# Import regression models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Hyperparameter tuning\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "ss = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba26c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6fd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45142376",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = datetime.datetime.now().year\n",
    "train['age'] = train['model_year'].apply(lambda x: year-x)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44466d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train[train.select_dtypes(include=['number']).drop(columns=['id']).columns].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6171eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['accident'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_train = train.isnull().sum()\n",
    "null_test = test.isnull().sum()\n",
    "null_df = pd.concat([null_train, null_test], axis=1, keys=['train', 'test'])\n",
    "null_df['% missing train'] = null_df['train']/len(train)\n",
    "null_df['% missing test'] = null_df['test']/len(test)\n",
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duplicate train: \", train.duplicated().sum())\n",
    "print(\"duplicate test: \", test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fuel_type.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fuel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d2f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['engine'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_missing_df = train[train['fuel_type'].isnull()]\n",
    "fuel_missing_df.brand.value_counts()\n",
    "# Tesla is electric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.clean_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5182b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_title_missing_df = train[train['clean_title'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "\n",
    "    year = datetime.datetime.now().year\n",
    "    df['age'] = df['model_year'].apply(lambda x: year-x)\n",
    "\n",
    "    df['risk_dead_engine'] = df['milage'].map(lambda x: 1 if x>300000 else 0)\n",
    "\n",
    "    def overworked(row):\n",
    "        if row['milage']>50000 and row['age']<1:\n",
    "            return 1\n",
    "        elif row['milage']>100000 and row['age']<2:\n",
    "            return 1\n",
    "        elif row['milage']>300000 and row['age']<10:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def fresh_engine(row):\n",
    "        if row['milage']<10000:\n",
    "            return 1\n",
    "        if row['milage']<30000 and row['age']>=2:\n",
    "            return 1\n",
    "        return 0\n",
    "    df['overworked'] = df.apply(overworked, axis=1)\n",
    "    df['fresh_engine'] = df.apply(fresh_engine, axis=1)\n",
    "\n",
    "\n",
    "    df['Cylinder'] = df['engine'].str.extract(r'(\\d+)\\s+Cylinder', expand=False).fillna(-1).astype(int)\n",
    "\n",
    "    df['engine_Litr'] = df['engine'].str.extract(r'(\\d+\\.\\d+)\\s+L', expand=False).fillna(-1).astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f00107",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test['id']\n",
    "def preprocess_data(train, test):\n",
    "\n",
    "    # drop duplicates\n",
    "    train = train.drop_duplicates()\n",
    "\n",
    "    # concat train and test\n",
    "    test['price'] = -1\n",
    "    df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "    # missing values :\n",
    "\n",
    "    ## fuel_type\n",
    "    mask = df['fuel_type'].isnull()\n",
    "    df.loc[mask, 'fuel_type'] = df.loc[mask, 'engine'].map(lambda x: 'Plug-In Hybrid' if 'Plug-In' in x else 'Hybrid' if 'Hybrid' in x else 'Gasoline' if 'Gasoline' in x else 'E85 Flex Fuel' if 'Flex Fuel' in x else  'Diesel' if 'Diesel|GDI' in x else 'Other')\n",
    "    ## clean_title\n",
    "    mask = df['clean_title'].isnull()\n",
    "    df.loc[mask, 'clean_title'] = 'No'\n",
    "    ## accident \n",
    "    mask = df['accident'].isnull()\n",
    "    df.loc[mask, 'accident'] = 'None reported'\n",
    "\n",
    "    # feature engineering\n",
    "    df = feature_engineering(df)\n",
    "\n",
    "\n",
    "    # drop null values\n",
    "    # df.dropna(inplace=True)\n",
    "\n",
    "    # drop cols\n",
    "    cols = ['id']\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # Encode categorical features\n",
    "    ## feature to one hot encoding\n",
    "    features_to_1hotEncode = ['accident']\n",
    "    df = pd.get_dummies(df, columns=features_to_1hotEncode)\n",
    "\n",
    "    train = df[df['price']!=-1]\n",
    "    test = df[df['price']==-1]\n",
    "\n",
    "    ## feature for label encoding\n",
    "    cols_to_LabelEncode = train.select_dtypes(include=['object']).columns\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for col in tqdm(cols_to_LabelEncode,desc='Encoding categorical features'):\n",
    "        if col in train.columns and col in test.columns:\n",
    "            classes_ = train[col].unique()\n",
    "            train[col] = le.fit_transform(train[col])\n",
    "            test[col] = test[col].map(lambda x: le.transform([x])[0] if x in classes_ else -1)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = preprocess_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.drop('price', axis=1), train['price'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ffc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = cb.CatBoostRegressor(loss_function='RMSE', verbose=0)\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression', metric='rmse', random_state=42,verbose=-1)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "models = [cat_model, xgb_model, lgb_model, rf_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae58252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters for each model\n",
    "    cat_params = {\n",
    "        'iterations': trial.suggest_int('cat_iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('cat_learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('cat_depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('cat_l2_leaf_reg', 1, 10)\n",
    "    }\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('xgb_subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0)\n",
    "    }\n",
    "    \n",
    "    lgb_params = {\n",
    "        'n_estimators': trial.suggest_int('lgb_n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('lgb_max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('lgb_subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('lgb_colsample_bytree', 0.6, 1.0)\n",
    "    }\n",
    "    \n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 5, 20),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 5)\n",
    "    }\n",
    "    \n",
    "    # Create models with suggested hyperparameters\n",
    "    cat_model = cb.CatBoostRegressor(loss_function='RMSE', verbose=0, **cat_params)\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, **xgb_params)\n",
    "    lgb_model = lgb.LGBMRegressor(objective='regression', metric='rmse', random_state=42, verbose=-1, **lgb_params)\n",
    "    rf_model = RandomForestRegressor(random_state=42, **rf_params)\n",
    "    \n",
    "    models = [cat_model, xgb_model, lgb_model, rf_model]\n",
    "    \n",
    "    # Train models and calculate ensemble RMSE and NRMSE\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    # Calculate ensemble prediction (average of all models)\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    rmse = root_mean_squared_error(y_test, ensemble_pred)\n",
    "    nrmse = rmse / (y_test.max() - y_test.min())\n",
    "    \n",
    "    # Store NRMSE in trial user attributes for comparison\n",
    "    trial.set_user_attr('nrmse', nrmse)\n",
    "    \n",
    "    return rmse  # Optimize for RMSE\n",
    "\n",
    "# Create study and optimize\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1837b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best trial:\")\n",
    "print(f\"RMSE: {study.best_value:.2f}\")\n",
    "print(f\"NRMSE: {study.best_trial.user_attrs['nrmse']:.4f}\")\n",
    "print(\"Best params:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update models with best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Extract parameters for each model\n",
    "cat_best_params = {k.replace('cat_', ''): v for k, v in best_params.items() if k.startswith('cat_')}\n",
    "xgb_best_params = {k.replace('xgb_', ''): v for k, v in best_params.items() if k.startswith('xgb_')}\n",
    "lgb_best_params = {k.replace('lgb_', ''): v for k, v in best_params.items() if k.startswith('lgb_')}\n",
    "rf_best_params = {k.replace('rf_', ''): v for k, v in best_params.items() if k.startswith('rf_')}\n",
    "\n",
    "# Create optimized models\n",
    "cat_model = cb.CatBoostRegressor(loss_function='RMSE', verbose=0, **cat_best_params)\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, **xgb_best_params)\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression', metric='rmse', random_state=42, verbose=-1, **lgb_best_params)\n",
    "rf_model = RandomForestRegressor(random_state=42, **rf_best_params)\n",
    "\n",
    "models = [cat_model, xgb_model, lgb_model, rf_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'submission'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = []\n",
    "\n",
    "# Remove 'price' column from test data if it exists\n",
    "test_features = test.drop('price', axis=1) if 'price' in test.columns else test\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train.drop('price', axis=1), train['price'])\n",
    "    pred = model.predict(test_features)\n",
    "    test_predictions.append(pred)\n",
    "    \n",
    "    # Create individual submission file for each model\n",
    "    model_submission = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'price': pred\n",
    "    })\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    model_submission.to_csv(f'{folder_name}/submission_{model_name}.csv', index=False)\n",
    "    print(f\"{model_name} submission file created successfully!\")\n",
    "\n",
    "# Create ensemble prediction (average of all models)\n",
    "ensemble_pred = np.mean(test_predictions, axis=0)\n",
    "\n",
    "# Create ensemble submission file\n",
    "ensemble_submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'price': ensemble_pred\n",
    "})\n",
    "\n",
    "ensemble_submission.to_csv(f'{folder_name}/submission_ensemble.csv', index=False)\n",
    "print(\"Ensemble submission file created successfully!\")\n",
    "print(ensemble_submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
